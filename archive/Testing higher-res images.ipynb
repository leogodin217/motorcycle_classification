{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python setup\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Sampler, Subset\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch import optim, cuda\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up paths\n",
    "base_path = Path('./clean_data/').absolute()\n",
    "raw_base_path = base_path / 'motorcycles'\n",
    "raw_train_path = str(raw_base_path / 'train')\n",
    "raw_val_path = str(raw_base_path / 'val')\n",
    "raw_test_path = str(raw_base_path / 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    '''\n",
    "    Creates a resnet-50 pretrained model and replaces the classifier with a new classifier\n",
    "    '''\n",
    "    model = models.resnet34(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    num_inputs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(nn.Linear(num_inputs, 256),\n",
    "                                       nn.ReLU(),\n",
    "                                       # Get rid of dropout. I will re-evaluate later\n",
    "                                       #nn.Dropout(0.4),\n",
    "                                       nn.Linear(256, num_classes),\n",
    "                                       nn.LogSoftmax(dim=1))\n",
    "    # Move to the GPU\n",
    "    model = model.to('cuda')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, dataloader, criterion, num_images, clear_cuda_cache=True):\n",
    "    '''\n",
    "    Performs a forward pass getting loss and accuracy, without modifying the model\n",
    "    model: A pytorch NN \n",
    "    data A pytorch Dataloader\n",
    "    clear_cuda_cache: Do we want to clear cuda memory when possible?\n",
    "    num_images: Int representing the number of images being processed. This is needed because\n",
    "                a sampler might return fewer results than the total dataset.\n",
    "    '''\n",
    "    total_loss = 0\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for data, target in dataloader:\n",
    "            data = data.to('cuda')\n",
    "            target = target.to('cuda')\n",
    "            result = model(data)\n",
    "            loss = criterion(result, target)\n",
    "            batch_loss = loss.item() * data.size(0)\n",
    "            total_loss += batch_loss\n",
    "            if clear_cuda_cache is True:\n",
    "                data = None\n",
    "                target = None\n",
    "                cuda.empty_cache()\n",
    "    mean_loss = total_loss / num_images\n",
    "    return({'mean_loss': mean_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, dataloader, num_images, clear_cuda_cache=True):\n",
    "    '''\n",
    "    Performs a forward pass getting loss and accuracy, without modifying the model\n",
    "    model: A pytorch NN \n",
    "    data A pytorch Dataloader\n",
    "    clear_cuda_cache: Do we want to clear cuda memory when possible?\n",
    "    num_images: Int representing the number of images being processed. This is needed because\n",
    "                a sampler might return fewer results than the total dataset.\n",
    "    '''\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for data, target in dataloader:\n",
    "            data = data.to('cuda')\n",
    "            target = target.to('cuda')\n",
    "            result = model(data)\n",
    "            _, predicted = torch.max(result.data, 1)\n",
    "            # Get accurate images\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "            if clear_cuda_cache is True:\n",
    "                data = None\n",
    "                target = None\n",
    "                cuda.empty_cache()\n",
    "    return correct_predictions / num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/ for hyperparameters\n",
    "# hyper parameters are set to the research recommendations\n",
    "def basic_train_model(dataloaders, epochs, clear_cuda_cache=True, name='basic model',\n",
    "                      alpha=.001, beta1=0.9, beta2=0.999, epsilon=10e-8, weight_decay=0):\n",
    "    '''\n",
    "    Very-early training function. Not much here, but the basics to train the\n",
    "    model and report loss and cuda memory\n",
    "    dataloader: A Pytorch dataloader with train, validation and test datasets. All dataloaders\n",
    "                should have the same number of classes\n",
    "    clear_cuda_cache: Boolean telling us to clear the cuda cache when possible\n",
    "    name: String with a name to give the model.\n",
    "    '''\n",
    "    all_start_time = datetime.now()\n",
    "    results = []\n",
    "    cuda_memory = []\n",
    "    \n",
    "    # The model changes with the number of classes, so we need to get that number.\n",
    "    # A dataset with a sampler, may not include all classes in the dataset, so we\n",
    "    # need to iterate to find the distinct classes\n",
    "    # We also need the number of images, with the same constraints as classes. We\n",
    "    # will calculate it here for accuracy\n",
    "    included_classes = []\n",
    "    num_images = 0\n",
    "    print('Gathering configurations')\n",
    "    config_start_time = datetime.now()\n",
    "    for item in dataloaders['train']:\n",
    "        included_classes = included_classes + item[1].tolist()\n",
    "        num_images += len(item[1])\n",
    "    num_classes = len(set(included_classes))\n",
    "    \n",
    "    # Get the number of val images returned in the dataloader. It could be a subset of the dataset if a sampler\n",
    "    # is used\n",
    "    num_val_images = 0\n",
    "    for item in dataloaders['val']:\n",
    "        num_val_images += len(item[1])\n",
    "        \n",
    "    # Get the number of images returned in the dataloader. It could be a subset of the dataset if a sampler\n",
    "    # is used\n",
    "    num_test_images = 0\n",
    "    for item in dataloaders['test']:\n",
    "        num_test_images += len(item[1])\n",
    "    config_end_time = datetime.now()\n",
    "    print(f\"Configuration: {config_end_time - config_start_time}\")\n",
    "    \n",
    "    print('Preparing model')\n",
    "    model_start_time = datetime.now()\n",
    "    model = get_model(num_classes)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=alpha, betas=(beta1, beta2), \n",
    "                           eps=epsilon, weight_decay=weight_decay)\n",
    "    model_end_time = datetime.now()\n",
    "    print(f'Model preparation: {model_end_time - model_start_time}')\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = datetime.now()\n",
    "        print(f'Epoch: {epoch + 1}')\n",
    "        train_loss = 0.0\n",
    "        for data, targets in dataloaders['train']:\n",
    "            #Get cuda memory\n",
    "            cuda_memory.append({\n",
    "                'name': name,\n",
    "                'timestamp': datetime.now(),\n",
    "                'cuda_memory': cuda.memory_allocated()})\n",
    "            data = data.to('cuda')\n",
    "            targets = targets.to('cuda')\n",
    "            cuda_memory.append({\n",
    "                'name': name,\n",
    "                'timestamp': datetime.now(),\n",
    "                'cuda_memory': cuda.memory_allocated()})\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(out, targets)\n",
    "            loss.backward()\n",
    "            # Get loss for the batch\n",
    "            batch_loss = loss.item() * data.size(0)\n",
    "            train_loss += batch_loss\n",
    "            optimizer.step()\n",
    "            #Get cuda memory\n",
    "            cuda_memory.append({\n",
    "                'name': name,\n",
    "                'timestamp': datetime.now(),\n",
    "                'cuda_memory': cuda.memory_allocated()})\n",
    "            # Clear the batch from cuda memory. It is no longer needed\n",
    "            if clear_cuda_cache is True:\n",
    "                data = None\n",
    "                targets = None\n",
    "                cuda.empty_cache()\n",
    "        \n",
    "        mean_train_loss = train_loss / num_images\n",
    "\n",
    "        # Get train accuracy to see if the model is learning at all\n",
    "        #train_accuracy = get_accuracy(model, dataloaders['train'], num_images)\n",
    "        # Get validation loss\n",
    "       \n",
    "        validation_results = forward_pass(model, dataloaders['val'], criterion, num_images=num_val_images,\n",
    "                                          clear_cuda_cache=clear_cuda_cache)\n",
    "        # Get test accuracy\n",
    "        test_accuracy = get_accuracy(model, dataloaders['test'], num_test_images)\n",
    "        epoch_end = datetime.now()\n",
    "        print(f'Epoch run time: {epoch_end - epoch_start}, Train_loss: {mean_train_loss}, Val loss: {validation_results[\"mean_loss\"]}, Test Accuracy: {test_accuracy}')\n",
    "        results.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'epoch_runtime': epoch_end - epoch_start,\n",
    "            'train_loss': mean_train_loss,\n",
    "            'val_loss': validation_results['mean_loss'],\n",
    "            'test_accuracy': test_accuracy})\n",
    "        \n",
    "    all_end_time = datetime.now()\n",
    "    return {'model': model, 'name': name, 'results': results, 'cuda_memory': cuda_memory, \n",
    "            'run_time': all_end_time - all_start_time, 'config_run_time': config_end_time - config_start_time,\n",
    "            'model_run_time': model_end_time - model_start_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "basic_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize using same mean, std as imagenet\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=512),\n",
    "        transforms.CenterCrop(size=448),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize using same mean, std as ResNet\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "basic_data = {\n",
    "    'train': datasets.ImageFolder(root=raw_train_path, transform = basic_transforms['train'] ),\n",
    "    'valid': datasets.ImageFolder(root=raw_val_path, transform = basic_transforms['valid']),\n",
    "    'test': datasets.ImageFolder(root=raw_test_path, transform = basic_transforms['valid'])\n",
    "}\n",
    "\n",
    "basic_dataloaders = {\n",
    "    'train': DataLoader(basic_data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(basic_data['valid'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(basic_data['test'], batch_size=batch_size, shuffle=True),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetSampler(Sampler):\n",
    "    '''\n",
    "    Sampler base on the number of targets we want. Rather than random sampling from all \n",
    "    targets, which may not have the same targets as test and train, we pull all images from \n",
    "    the first x number of targets\n",
    "    \n",
    "    This was extremely slow at first, because I was iterating through the data instead of \n",
    "    just the targets. Now it takes no noticable time\n",
    "\n",
    "    '''\n",
    "    def __init__(self, data, num_targets):\n",
    "        '''\n",
    "        data: A pytorch dataset (In this case, an ImageFolder)\n",
    "        num_targets: Int representing the first X targets to use.\n",
    "        '''\n",
    "        self.num_targets = num_targets\n",
    "        self.data = data\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = []\n",
    "        for index, target in enumerate(self.data.targets):\n",
    "            # Add the indice if the target is in range\n",
    "            if target < self.num_targets:\n",
    "                indices.append(index)\n",
    "        return iter(indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Count the number of images in the target range\n",
    "        # The image is a tuple, with image[1] being the target\n",
    "        return len([i for i in self.data.targets if i < self.num_targets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targets = 50\n",
    "num_epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering configurations\n",
      "Configuration: 0:00:27.534185\n",
      "Preparing model\n",
      "Model preparation: 0:00:00.981706\n",
      "Epoch: 1\n",
      "Epoch run time: 0:00:30.066453, Train_loss: 4.07114200592041, Val loss: 3.891035556793213, Test Accuracy: 0.056818181818181816\n",
      "Epoch: 2\n",
      "Epoch run time: 0:00:30.107382, Train_loss: 3.8418405437469483, Val loss: 3.8656692504882812, Test Accuracy: 0.06818181818181818\n",
      "Epoch: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6e1a4ea7a647>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m basic_data_basic_model = basic_train_model(dataloaders=high_res_basic, epochs=num_epochs, alpha=0.001,\n\u001b[1;32m---> 13\u001b[1;33m                                      name='512x512 Basic data and transforms', clear_cuda_cache=True)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_data_basic_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'run_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-caa46e9c0375>\u001b[0m in \u001b[0;36mbasic_train_model\u001b[1;34m(dataloaders, epochs, clear_cuda_cache, name, alpha, beta1, beta2, epsilon, weight_decay)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch: {epoch + 1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[1;31m#Get cuda memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             cuda_memory.append({\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \"\"\"\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sampler = TargetSampler(basic_data['train'], num_targets=num_targets)\n",
    "val_sampler = TargetSampler(basic_data['valid'], num_targets=num_targets)\n",
    "test_sampler = TargetSampler(basic_data['test'], num_targets=num_targets)\n",
    "\n",
    "high_res_basic = {\n",
    "    'train': DataLoader(basic_data['train'], batch_size=batch_size, sampler=train_sampler, shuffle=False),\n",
    "    'val': DataLoader(basic_data['valid'], batch_size=batch_size, sampler=val_sampler, shuffle=False),\n",
    "    'test': DataLoader(basic_data['test'], batch_size=batch_size, sampler=test_sampler, shuffle=False)\n",
    "}\n",
    "\n",
    "\n",
    "basic_data_basic_model = basic_train_model(dataloaders=high_res_basic, epochs=num_epochs, alpha=0.001,\n",
    "                                     name='512x512 Basic data and transforms', clear_cuda_cache=True)\n",
    "print(basic_data_basic_model['run_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basic_data_basic_model['model']\n",
    "with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for data, target in basic_data_basic_model['test']:\n",
    "            data = data.to('cuda')\n",
    "            target = target.to('cuda')\n",
    "            result = model(data)\n",
    "            _, predicted = torch.max(result.data, 1)\n",
    "            # Get accurate images\n",
    "            #correct_predictions += (predicted == target).sum().item()\n",
    "            print(f'Predicted: {predicted}, Actual: {target}')\n",
    "            data = None\n",
    "            target = None\n",
    "            cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet34.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#resnet34.bn1 = nn.BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.resnet34()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
