{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch import optim, cuda\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up paths\n",
    "base_path = Path('./clean_data/').absolute()\n",
    "raw_base_path = base_path / 'motorcycles'\n",
    "raw_train_path = str(raw_base_path / 'train')\n",
    "raw_val_path = str(raw_base_path / 'val')\n",
    "raw_test_path = str(raw_base_path / 'test')\n",
    "square_base_path = base_path / 'square_motorcycles'\n",
    "square_train_path = str(square_base_path / 'train')\n",
    "square_val_path = str(square_base_path / 'val')\n",
    "square_test_path = str(square_base_path / 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n",
      "1 gpus detected.\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "batch_size = 256 # Make smaller if running out of memory\n",
    "num_classes = 0 # Will update after we load in the data\n",
    "num_inputs = 0 # Will update once our model is selected\n",
    "num_epochs = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create our transforms. In this case, we will simply resize and center crop, then normalize using the same normalization settings as ResNet-34. Then we create our data and loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize using same mean, std as imagenet\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize using same mean, std as ResNet\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "    'train': datasets.ImageFolder(root=raw_train_path, transform = raw_transforms['train'] ),\n",
    "    'valid': datasets.ImageFolder(root=raw_val_path, transform = raw_transforms['valid'])\n",
    "}\n",
    "\n",
    "raw_dataloaders = {\n",
    "    'train': DataLoader(raw_data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(raw_data['valid'], batch_size=batch_size, shuffle=True)\n",
    "}\n",
    "\n",
    "num_classes = len(raw_data['train'].classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will create a CNN using the pretrained ResNet-34. We set all layers to autograd=False, so that we are not changing weights and biases on them. Then we will add a classifier. Later on, we will create a function to make all of this easier for playing with settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "If we look at modle.fc, I believe we are seeing the final connected layer. This is the part of the model that applies a target. \n",
    "We will replace this with four new layers. These will be an additional convolution and a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(model.fc)\n",
    "\n",
    "num_inputs = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_inputs, 256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.4),\n",
    "                                   nn.Linear(256, num_classes),\n",
    "                                   nn.LogSoftmax(dim=1))\n",
    "# Move to the GPU\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very basic model, without great transforms, no hyperparameters, and little tracking. But, it should work to see if things are moving in the right direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    train_loss = 0.0\n",
    "    for data, targets in raw_dataloaders['train']:\n",
    "        data = data.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        out = model(data)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "        # Get loss for the batch\n",
    "        batch_loss = loss.item() * data.size(0)\n",
    "        train_loss += batch_loss\n",
    "        optimizer.step()\n",
    "        #data = None\n",
    "        #targets = None\n",
    "        #cuda.empty_cache()\n",
    "    print(f'Train_loss: {train_loss}')\n",
    "    results.append({'data': 'raw images', 'epoch': epoch + 1, 'train_loss': train_loss})\n",
    "# model = None\n",
    "# cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on the data we made square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize using same mean, std as imagenet\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize using same mean, std as imagenet\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "square_data = {\n",
    "    'train': datasets.ImageFolder(root=square_train_path, transform = square_transforms['train'] ),\n",
    "    'valid': datasets.ImageFolder(root=square_val_path, transform = square_transforms['valid'])\n",
    "}\n",
    "\n",
    "square_dataloaders = {\n",
    "    'train': DataLoader(square_data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(square_data['valid'], batch_size=batch_size, shuffle=True)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(square_data['train'].classes)\n",
    "\n",
    "model = models.resnet34(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(model.fc)\n",
    "\n",
    "num_inputs = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_inputs, 256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(0.4),\n",
    "                                   nn.Linear(256, num_classes),\n",
    "                                   nn.LogSoftmax(dim=1))\n",
    "# Move to the GPU\n",
    "model = model.to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    train_loss = 0.0\n",
    "    for data, targets in square_dataloaders['train']:\n",
    "        data = data.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        out = model(data)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "        # Get loss for the batch\n",
    "        batch_loss = loss.item() * data.size(0)\n",
    "        train_loss += batch_loss\n",
    "        optimizer.step()\n",
    "        #data = None\n",
    "        #targets = None\n",
    "        #cuda.empty_cache()\n",
    "        # Get cuda memory\n",
    "        cuda_memory.append({\n",
    "            'method': 'no clearing cache', \n",
    "            'timestamp': datetime.now().timestamp(),  \n",
    "            'cuda_memory': cuda.memory_allocated()})\n",
    "    print(f'Train_loss: {train_loss}')\n",
    "    results.append({'data': 'square images', 'epoch': epoch + 1, 'train_loss': train_loss})\n",
    "#model = None\n",
    "#cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_train_model(data, dataloaders, epochs, clear_cuda_cache=True, name='basic model'):\n",
    "    '''\n",
    "    Very-early training function. Not much here, but the basics to train the\n",
    "    model and report loss and cuda memory\n",
    "    data: A pytorch dataset with train and val data\n",
    "    dataloader: A Pytorch dataloader with train and validation datasets\n",
    "    clear_cuda_cache: Boolean telling us to clear the cuda cache when possible\n",
    "    name: String with a name to give the model.\n",
    "    '''\n",
    "    start_time = datetime.now()\n",
    "    results = []\n",
    "    cuda_memory = []\n",
    "    num_classes = len(data['train'].classes)\n",
    "\n",
    "    model = models.resnet34(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    num_inputs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(nn.Linear(num_inputs, 256),\n",
    "                                       nn.ReLU(),\n",
    "                                       # Get rid of dropout. I will re-evaluate later\n",
    "                                       #nn.Dropout(0.4),\n",
    "                                       nn.Linear(256, num_classes),\n",
    "                                       nn.LogSoftmax(dim=1))\n",
    "    # Move to the GPU\n",
    "    model = model.to('cuda')\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {epoch + 1}')\n",
    "        train_loss = 0.0\n",
    "        for data, targets in dataloaders['train']:\n",
    "             #Get cuda memory\n",
    "            cuda_memory.append({\n",
    "                'name': name,\n",
    "                'timestamp': datetime.now(),\n",
    "                'cuda_memory': cuda.memory_allocated()})\n",
    "            data = data.to('cuda')\n",
    "            targets = targets.to('cuda')\n",
    "            cuda_memory.append({\n",
    "                'name': name,\n",
    "                'timestamp': datetime.now(),\n",
    "                'cuda_memory': cuda.memory_allocated()})\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            \n",
    "            loss = criterion(out, targets)\n",
    "            # clear the graidients or they will accumulate\n",
    "            \n",
    "            loss.backward()\n",
    "            # Get loss for the batch\n",
    "            batch_loss = loss.item() * data.size(0)\n",
    "            train_loss += batch_loss\n",
    "            optimizer.step()\n",
    "            #Get cuda memory\n",
    "            cuda_memory.append({\n",
    "                'name': name,\n",
    "                'timestamp': datetime.now(),\n",
    "                'cuda_memory': cuda.memory_allocated()})\n",
    "            # Clear the batch from cuda memory. It is no longer needed\n",
    "            if clear_cuda_cache is True:\n",
    "                data = None\n",
    "                targets = None\n",
    "                cuda.empty_cache()\n",
    "            \n",
    "        print(f'Train_loss: {train_loss}')\n",
    "        results.append({\n",
    "            'data': 'square images',\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss})\n",
    "    end_time = datetime.now()\n",
    "    return {'model': model, 'name': name, 'train_loss': train_loss, 'cuda_memory': cuda_memory, \n",
    "            'run_time': end_time - start_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train_loss: 9178.373175621033\n",
      "Epoch: 2\n",
      "Train_loss: 9067.50984954834\n",
      "Epoch: 3\n",
      "Train_loss: 9053.591597557068\n",
      "Epoch: 4\n",
      "Train_loss: 9043.208864212036\n",
      "Epoch: 5\n",
      "Train_loss: 9033.444452285767\n",
      "Epoch: 6\n",
      "Train_loss: 9017.467531204224\n",
      "Epoch: 7\n",
      "Train_loss: 8988.775751113892\n",
      "Epoch: 8\n",
      "Train_loss: 8968.493178367615\n",
      "Epoch: 9\n",
      "Train_loss: 8950.81909942627\n",
      "Epoch: 10\n",
      "Train_loss: 8943.764300346375\n",
      "Epoch: 11\n",
      "Train_loss: 8918.916849136353\n",
      "Epoch: 12\n",
      "Train_loss: 8895.64979171753\n",
      "Epoch: 13\n",
      "Train_loss: 8873.114252090454\n",
      "Epoch: 14\n",
      "Train_loss: 8864.470151901245\n",
      "Epoch: 15\n",
      "Train_loss: 8839.355823516846\n",
      "Epoch: 16\n",
      "Train_loss: 8805.560286521912\n",
      "Epoch: 17\n",
      "Train_loss: 8805.328288078308\n",
      "Epoch: 18\n",
      "Train_loss: 8766.316045761108\n",
      "Epoch: 19\n",
      "Train_loss: 8707.695014953613\n",
      "Epoch: 20\n",
      "Train_loss: 8701.306518554688\n",
      "Epoch: 21\n",
      "Train_loss: 8712.221153259277\n",
      "Epoch: 22\n",
      "Train_loss: 8665.408208847046\n",
      "Epoch: 23\n",
      "Train_loss: 8643.866147994995\n",
      "Epoch: 24\n",
      "Train_loss: 8621.163217544556\n",
      "Epoch: 25\n",
      "Train_loss: 8611.817869186401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"square_results_clear_cache = basic_train_model(data=square_data, dataloaders=raw_dataloaders, epochs=5, \\n                                               name='Square images with clear', clear_cuda_cache=True)\\nraw_results = basic_train_model(data=raw_data, dataloaders=raw_dataloaders, epochs=5, \\n                                name='Raw images no clear', clear_cuda_cache=False)\\nsquare_results = basic_train_model(data=square_data, dataloaders=raw_dataloaders, epochs=5, \\n                                   name='Square images no clear', clear_cuda_cache=False)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_results_clear_cache = basic_train_model(data=raw_data, dataloaders=raw_dataloaders, epochs=25, \n",
    "                                            name='Raw images with clear', clear_cuda_cache=True)\n",
    "'''square_results_clear_cache = basic_train_model(data=square_data, dataloaders=raw_dataloaders, epochs=5, \n",
    "                                               name='Square images with clear', clear_cuda_cache=True)\n",
    "raw_results = basic_train_model(data=raw_data, dataloaders=raw_dataloaders, epochs=5, \n",
    "                                name='Raw images no clear', clear_cuda_cache=False)\n",
    "square_results = basic_train_model(data=square_data, dataloaders=raw_dataloaders, epochs=5, \n",
    "                                   name='Square images no clear', clear_cuda_cache=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_results['run_time'])\n",
    "print(raw_results_clear_cache['run_time'])\n",
    "print(square_results['run_time'])\n",
    "print(square_results_clear_cache['run_time'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_clear = pd.DataFrame(raw_results['cuda_memory'])\n",
    "no_clear = no_clear.set_index('timestamp')\n",
    "no_clear.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_clear = pd.DataFrame(raw_results_clear_cache['cuda_memory'])\n",
    "with_clear = with_clear.set_index('timestamp')\n",
    "with_clear.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002631093D930>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_results_clear_cache['model'].parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
